{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import sys\n",
    "import glob\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from pandas.plotting import register_matplotlib_converters\n",
    "register_matplotlib_converters()\n",
    "sns.set_style('darkgrid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## parameters \n",
    "lowtrunc = 0\n",
    "hightrunc = 7000\n",
    "avgp = 15\n",
    "\n",
    "train = pd.read_csv(\"train.csv\")\n",
    "train_frags = glob.glob(\"./train_fft/*\")\n",
    "len(train_frags)\n",
    "\n",
    "all_df = pd.DataFrame() \n",
    "ertime = pd.Series(0, index=np.arange(len(train_frags)))\n",
    "\n",
    "i = 0\n",
    "for file in train_frags:\n",
    "#     print('file',file)\n",
    "    start = './train_fft/'\n",
    "    end = '.csv'\n",
    "    seg_id = file[file.find(start)+len(start):file.rfind(end)]\n",
    "#     print('segment_id',seg_id)\n",
    "    t2e = int(train.loc[train['segment_id'] == int(seg_id)]['time_to_eruption'].values)\n",
    "#     print('time to eruption',t2e)\n",
    "\n",
    "\n",
    "    ## let's combine the fft's of the sensors\n",
    "    sequence = pd.read_csv(file)\n",
    "    ## create composite of sensors frequenc domain\n",
    "    composite = sequence.sum(axis=1) / len(sequence.columns)\n",
    "    ## Truncate low frequency noise\n",
    "    composite = composite[lowtrunc:-hightrunc]\n",
    "    ## smooth signal with average\n",
    "    composite = composite.rolling(avgp, win_type='triang').sum()\n",
    "    composite = composite.fillna(0)\n",
    "    ## min-max scale signal\n",
    "    composite = (composite - composite.min()) / (composite.max() - composite.min())\n",
    "#     print('time to eruption',t2e)\n",
    "#     print('skew',composite.skew())\n",
    "#     print('kurtosis',composite.kurt())\n",
    "    ## Build DataFrame\n",
    "    all_df = all_df.append(composite,ignore_index=True)\n",
    "    ertime.iloc[i] = t2e\n",
    "    i = i + 1\n",
    "\n",
    "test_frags = glob.glob(\"./test_fft/*\")\n",
    "len(test_frags)\n",
    "\n",
    "test_id = pd.Series(0, index=np.arange(len(test_frags)))\n",
    "\n",
    "i = 0\n",
    "for file in test_frags:\n",
    "#     print('file',file)\n",
    "    start = './test_fft/'\n",
    "    end = '.csv'\n",
    "    seg_id = file[file.find(start)+len(start):file.rfind(end)]\n",
    "\n",
    "    ## let's combine the fft's of the sensors\n",
    "    sequence = pd.read_csv(file)\n",
    "    ## create composite of sensors frequenc domain\n",
    "    composite = sequence.sum(axis=1) / len(sequence.columns)\n",
    "    ## Truncate low frequency noise\n",
    "    composite = composite[lowtrunc:-hightrunc]\n",
    "    ## smooth signal with average\n",
    "    composite = composite.rolling(avgp, win_type='triang').sum()\n",
    "    composite = composite.fillna(0)\n",
    "    ## min-max scale signal\n",
    "    composite = (composite - composite.min()) / (composite.max() - composite.min())\n",
    "\n",
    "    ## Build DataFrame\n",
    "    all_df = all_df.append(composite,ignore_index=True)\n",
    "    test_id.iloc[i] = seg_id\n",
    "    i = i + 1\n",
    "#     xf = np.linspace(0.0, 1.0/(2.0*1/100.0), len(composite))\n",
    "#     plt.axis([0, 50, 0, 1])\n",
    "#     plt.plot(xf, composite)\n",
    "#     plt.grid()\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 8951 entries, 0 to 8950\n",
      "Columns: 23000 entries, 0 to 22999\n",
      "dtypes: float64(23000)\n",
      "memory usage: 1.5 GB\n"
     ]
    }
   ],
   "source": [
    "all_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "npca = 55\n",
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=npca,whiten=True)\n",
    "pca_fit = pca.fit(all_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_pca = pca_fit.transform(all_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = pd.DataFrame(data=all_pca)\n",
    "out.to_csv('pca_55.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
