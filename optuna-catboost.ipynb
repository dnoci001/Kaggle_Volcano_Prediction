{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "from time import time\n",
    "from time import ctime\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from tqdm import tqdm_notebook\n",
    "from tqdm import tqdm\n",
    "\n",
    "import joblib\n",
    "from joblib import Parallel, delayed\n",
    "import multiprocessing\n",
    "num_cores = multiprocessing.cpu_count()-1\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import r2_score\n",
    "from catboost import CatBoostRegressor, Pool\n",
    "from sklearn.model_selection import KFold\n",
    "import matplotlib.pyplot as plt\n",
    "import optuna\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('/home/dominique/Projects/predict_volcanic_eruptions/tfresh/train.csv', sep = ';')\n",
    "train.set_index('Unnamed: 0', inplace = True)\n",
    "test = pd.read_csv('/home/dominique/Projects/predict_volcanic_eruptions/tfresh/test.csv', sep = ';')\n",
    "test.set_index('Unnamed: 0', inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.fillna(0, inplace=True)\n",
    "test.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "\n",
    "    Y = train['time_to_eruption']\n",
    "    X = train.drop(['time_to_eruption'], axis = 1)\n",
    "    X_test = test\n",
    "\n",
    "    n_fold = 3\n",
    "    cv = KFold(n_splits=n_fold, shuffle=True, random_state=42)\n",
    "\n",
    "    oof = np.zeros(len(X))\n",
    "    cat_prediction = np.zeros(len(X_test))\n",
    "    mae, r2 = [], []\n",
    "\n",
    "    PARAMS = {\n",
    "                 'random_seed': 42,\n",
    "                 'eval_metric': 'MAE', #Also used as the eval metric for competition\n",
    "                 'iterations': 100,\n",
    "                 'eta': trial.suggest_float('eta',0.03,0.1),\n",
    "                 'subsample': trial.suggest_float('subsample',0.7,1.0),\n",
    "                 'l2_leaf_reg' : trial.suggest_float(\"lambda_l2\", 1e-3, 10.0, log=True),\n",
    "            }\n",
    "\n",
    "    for fold_n, (train_index, valid_index) in enumerate(cv.split(X)):\n",
    "\n",
    "        X_train = X.iloc[train_index,:]\n",
    "        X_valid = X.iloc[valid_index,:]\n",
    "\n",
    "        Y_train = Y.iloc[train_index]\n",
    "        Y_valid = Y.iloc[valid_index]\n",
    "\n",
    "        best_model = CatBoostRegressor(**PARAMS, thread_count = -1)  \n",
    "\n",
    "        train_dataset = Pool(data=X_train,\n",
    "                         label=Y_train,\n",
    "                         )\n",
    "\n",
    "        eval_dataset = Pool(data=X_valid,\n",
    "                        label=Y_valid,\n",
    "                        )\n",
    "\n",
    "        best_model.fit(train_dataset,\n",
    "                  use_best_model=True,\n",
    "                  verbose = False,\n",
    "                  eval_set=eval_dataset)\n",
    "\n",
    "\n",
    "        y_pred = best_model.predict(Pool(data=X_valid))\n",
    "\n",
    "        mae.append(mean_absolute_error(Y_valid, y_pred))\n",
    "        r2.append(r2_score(Y_valid, y_pred))\n",
    "\n",
    "        cat_prediction += best_model.predict(Pool(data=X_test))\n",
    "\n",
    "    cat_prediction /= n_fold\n",
    "\n",
    "    \n",
    "    submission = pd.DataFrame()\n",
    "    submission['segment_id'] = test.index\n",
    "    submission['time_to_eruption'] = cat_prediction\n",
    "    filename = 'submission' + str(trial.number) + '.csv'\n",
    "    submission.to_csv(filename, header=True, index=False)\n",
    "\n",
    "    return np.mean(mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-01-03 11:05:31,794]\u001b[0m A new study created in RDB with name: catboost_study\u001b[0m\n",
      "\u001b[32m[I 2021-01-03 11:08:53,577]\u001b[0m Trial 0 finished with value: 4357952.643601052 and parameters: {'eta': 0.054550770840884305, 'subsample': 0.8649195956926303, 'lambda_l2': 1.069135491556745}. Best is trial 0 with value: 4357952.643601052.\u001b[0m\n",
      "\u001b[32m[I 2021-01-03 11:12:20,466]\u001b[0m Trial 1 finished with value: 4031533.7252757885 and parameters: {'eta': 0.06624779674892628, 'subsample': 0.965679144214151, 'lambda_l2': 0.005849454769326836}. Best is trial 1 with value: 4031533.7252757885.\u001b[0m\n",
      "\u001b[32m[I 2021-01-03 11:15:30,077]\u001b[0m Trial 2 finished with value: 3771358.230286442 and parameters: {'eta': 0.08046687177352446, 'subsample': 0.7105190151848181, 'lambda_l2': 0.027606123272599214}. Best is trial 2 with value: 3771358.230286442.\u001b[0m\n",
      "\u001b[32m[I 2021-01-03 11:18:35,504]\u001b[0m Trial 3 finished with value: 4020309.7821647148 and parameters: {'eta': 0.06917166555386861, 'subsample': 0.8653965489539628, 'lambda_l2': 0.8751717932040354}. Best is trial 2 with value: 3771358.230286442.\u001b[0m\n",
      "\u001b[32m[I 2021-01-03 11:21:40,003]\u001b[0m Trial 4 finished with value: 3984507.4967114814 and parameters: {'eta': 0.0685613611121263, 'subsample': 0.7034493935320777, 'lambda_l2': 0.11960734271646077}. Best is trial 2 with value: 3771358.230286442.\u001b[0m\n",
      "\u001b[32m[I 2021-01-03 11:24:46,336]\u001b[0m Trial 5 finished with value: 3939751.551795576 and parameters: {'eta': 0.071076782321249, 'subsample': 0.9128971097221656, 'lambda_l2': 0.022363464450255614}. Best is trial 2 with value: 3771358.230286442.\u001b[0m\n",
      "\u001b[32m[I 2021-01-03 11:27:52,943]\u001b[0m Trial 6 finished with value: 3848088.704240132 and parameters: {'eta': 0.07351359366255189, 'subsample': 0.9135061564846514, 'lambda_l2': 0.0028736159195232353}. Best is trial 2 with value: 3771358.230286442.\u001b[0m\n",
      "\u001b[32m[I 2021-01-03 11:30:59,067]\u001b[0m Trial 7 finished with value: 5216231.053986053 and parameters: {'eta': 0.034898692074510136, 'subsample': 0.8212718019863874, 'lambda_l2': 0.0532751014759604}. Best is trial 2 with value: 3771358.230286442.\u001b[0m\n",
      "\u001b[32m[I 2021-01-03 11:34:06,137]\u001b[0m Trial 8 finished with value: 3798579.8564903117 and parameters: {'eta': 0.07491542848848332, 'subsample': 0.9441563055869384, 'lambda_l2': 0.06464255435654416}. Best is trial 2 with value: 3771358.230286442.\u001b[0m\n",
      "\u001b[32m[I 2021-01-03 11:37:15,790]\u001b[0m Trial 9 finished with value: 4049913.768924358 and parameters: {'eta': 0.06667983734807095, 'subsample': 0.746427680725091, 'lambda_l2': 0.022518688725461807}. Best is trial 2 with value: 3771358.230286442.\u001b[0m\n",
      "\u001b[32m[I 2021-01-03 11:41:15,516]\u001b[0m Trial 10 finished with value: 3863685.668258445 and parameters: {'eta': 0.08721957581192241, 'subsample': 0.774896075336267, 'lambda_l2': 5.357271319971697}. Best is trial 2 with value: 3771358.230286442.\u001b[0m\n",
      "\u001b[32m[I 2021-01-03 11:44:40,652]\u001b[0m Trial 11 finished with value: 3510817.4018982872 and parameters: {'eta': 0.09435202181558053, 'subsample': 0.9579862054596353, 'lambda_l2': 0.332707919970661}. Best is trial 11 with value: 3510817.4018982872.\u001b[0m\n",
      "\u001b[32m[I 2021-01-03 11:47:47,471]\u001b[0m Trial 12 finished with value: 3421374.7365498506 and parameters: {'eta': 0.09968254848461477, 'subsample': 0.989357949701885, 'lambda_l2': 0.4887313635193197}. Best is trial 12 with value: 3421374.7365498506.\u001b[0m\n",
      "\u001b[32m[I 2021-01-03 11:50:58,936]\u001b[0m Trial 13 finished with value: 3479577.1972402427 and parameters: {'eta': 0.09810839773948082, 'subsample': 0.9909196508978848, 'lambda_l2': 0.4314752042192042}. Best is trial 12 with value: 3421374.7365498506.\u001b[0m\n",
      "\u001b[32m[I 2021-01-03 11:55:01,722]\u001b[0m Trial 14 finished with value: 3669611.0266040307 and parameters: {'eta': 0.0996974004160493, 'subsample': 0.9955310812742714, 'lambda_l2': 7.5464787697851445}. Best is trial 12 with value: 3421374.7365498506.\u001b[0m\n",
      "\u001b[32m[I 2021-01-03 11:58:06,807]\u001b[0m Trial 15 finished with value: 3541177.6537399185 and parameters: {'eta': 0.09994027278357567, 'subsample': 0.9941754855670863, 'lambda_l2': 2.049528232752314}. Best is trial 12 with value: 3421374.7365498506.\u001b[0m\n",
      "\u001b[32m[I 2021-01-03 12:01:11,848]\u001b[0m Trial 16 finished with value: 4361393.211415365 and parameters: {'eta': 0.05209129897660094, 'subsample': 0.9939326503341942, 'lambda_l2': 0.3667955858880805}. Best is trial 12 with value: 3421374.7365498506.\u001b[0m\n",
      "\u001b[32m[I 2021-01-03 12:04:16,458]\u001b[0m Trial 17 finished with value: 3573917.4412377947 and parameters: {'eta': 0.0898766346810181, 'subsample': 0.9061300478310411, 'lambda_l2': 0.2501735478154385}. Best is trial 12 with value: 3421374.7365498506.\u001b[0m\n",
      "\u001b[32m[I 2021-01-03 12:07:20,896]\u001b[0m Trial 18 finished with value: 3755645.169492848 and parameters: {'eta': 0.0851174302429802, 'subsample': 0.9369394550714425, 'lambda_l2': 2.142790278700982}. Best is trial 12 with value: 3421374.7365498506.\u001b[0m\n",
      "\u001b[32m[I 2021-01-03 12:10:21,662]\u001b[0m Trial 19 finished with value: 3529731.1744940537 and parameters: {'eta': 0.09530514590220035, 'subsample': 0.825767543270651, 'lambda_l2': 0.762084783455144}. Best is trial 12 with value: 3421374.7365498506.\u001b[0m\n",
      "\u001b[32m[I 2021-01-03 12:13:16,650]\u001b[0m Trial 20 finished with value: 4427768.232203473 and parameters: {'eta': 0.05487733381796806, 'subsample': 0.9980013791537129, 'lambda_l2': 3.1559891138382787}. Best is trial 12 with value: 3421374.7365498506.\u001b[0m\n",
      "\u001b[32m[I 2021-01-03 12:16:11,298]\u001b[0m Trial 21 finished with value: 3515582.1137979515 and parameters: {'eta': 0.09440922475885083, 'subsample': 0.9698308801767568, 'lambda_l2': 0.2754540100445278}. Best is trial 12 with value: 3421374.7365498506.\u001b[0m\n",
      "\u001b[32m[I 2021-01-03 12:19:06,099]\u001b[0m Trial 22 finished with value: 3464719.7405647305 and parameters: {'eta': 0.0983913793402158, 'subsample': 0.965648076811416, 'lambda_l2': 0.14561794750190254}. Best is trial 12 with value: 3421374.7365498506.\u001b[0m\n",
      "\u001b[32m[I 2021-01-03 12:22:00,943]\u001b[0m Trial 23 finished with value: 3714311.379415102 and parameters: {'eta': 0.08067834353881688, 'subsample': 0.9774812666662221, 'lambda_l2': 0.13555156973694116}. Best is trial 12 with value: 3421374.7365498506.\u001b[0m\n",
      "\u001b[32m[I 2021-01-03 12:24:55,350]\u001b[0m Trial 24 finished with value: 3467174.16418316 and parameters: {'eta': 0.09761694615492884, 'subsample': 0.9420586666977806, 'lambda_l2': 0.8085304766527712}. Best is trial 12 with value: 3421374.7365498506.\u001b[0m\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-5ea65f6b14c3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mstudy_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'catboost_study'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mstudy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptuna\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_study\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirection\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"minimize\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mload_if_exists\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mstudy_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstudy_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstorage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'sqlite:///catboost_study.db'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mstudy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobjective\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_trials\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/optuna/study.py\u001b[0m in \u001b[0;36moptimize\u001b[0;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m    304\u001b[0m                 \u001b[0mIf\u001b[0m \u001b[0mnested\u001b[0m \u001b[0minvocation\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthis\u001b[0m \u001b[0mmethod\u001b[0m \u001b[0moccurs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    305\u001b[0m         \"\"\"\n\u001b[0;32m--> 306\u001b[0;31m         _optimize(\n\u001b[0m\u001b[1;32m    307\u001b[0m             \u001b[0mstudy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    308\u001b[0m             \u001b[0mfunc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/optuna/_optimize.py\u001b[0m in \u001b[0;36m_optimize\u001b[0;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mn_jobs\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m             _optimize_sequential(\n\u001b[0m\u001b[1;32m     56\u001b[0m                 \u001b[0mstudy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m                 \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/optuna/_optimize.py\u001b[0m in \u001b[0;36m_optimize_sequential\u001b[0;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[1;32m    154\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 156\u001b[0;31m             \u001b[0mtrial\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_run_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstudy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    157\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m             \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/optuna/_optimize.py\u001b[0m in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    187\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 189\u001b[0;31m         \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    190\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrialPruned\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m         \u001b[0;31m# Register the last intermediate value if present as the value of the trial.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-c0161cdd155f>\u001b[0m in \u001b[0;36mobjective\u001b[0;34m(trial)\u001b[0m\n\u001b[1;32m     39\u001b[0m                         )\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m         best_model.fit(train_dataset,\n\u001b[0m\u001b[1;32m     42\u001b[0m                   \u001b[0muse_best_model\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m                   \u001b[0mverbose\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/catboost/core.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, cat_features, sample_weight, baseline, use_best_model, eval_set, verbose, logging_level, plot, column_description, verbose_eval, metric_period, silent, early_stopping_rounds, save_snapshot, snapshot_file, snapshot_interval, init_model)\u001b[0m\n\u001b[1;32m   4845\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_is_regressor_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'loss_function'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4846\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4847\u001b[0;31m         return self._fit(X, y, cat_features, None, None, None, sample_weight, None, None, None, None, baseline,\n\u001b[0m\u001b[1;32m   4848\u001b[0m                          \u001b[0muse_best_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogging_level\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumn_description\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4849\u001b[0m                          \u001b[0mverbose_eval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetric_period\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msilent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mearly_stopping_rounds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/catboost/core.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X, y, cat_features, text_features, embedding_features, pairs, sample_weight, group_id, group_weight, subgroup_id, pairs_weight, baseline, use_best_model, eval_set, verbose, logging_level, plot, column_description, verbose_eval, metric_period, silent, early_stopping_rounds, save_snapshot, snapshot_file, snapshot_interval, init_model)\u001b[0m\n\u001b[1;32m   1802\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1803\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mlog_fixup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplot_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0m_get_train_dir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1804\u001b[0;31m             self._train(\n\u001b[0m\u001b[1;32m   1805\u001b[0m                 \u001b[0mtrain_pool\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1806\u001b[0m                 \u001b[0mtrain_params\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"eval_sets\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/catboost/core.py\u001b[0m in \u001b[0;36m_train\u001b[0;34m(self, train_pool, test_pool, params, allow_clear_pool, init_model)\u001b[0m\n\u001b[1;32m   1256\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1257\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_pool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_pool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_clear_pool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minit_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1258\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_object\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_pool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_pool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_clear_pool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minit_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_object\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0minit_model\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1259\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_trained_model_attributes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1260\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m_catboost.pyx\u001b[0m in \u001b[0;36m_catboost._CatBoost._train\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m_catboost.pyx\u001b[0m in \u001b[0;36m_catboost._CatBoost._train\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "study_name = 'catboost_study' \n",
    "study = optuna.create_study(direction=\"minimize\",load_if_exists = True,study_name=study_name, storage='sqlite:///catboost_study.db')\n",
    "study.optimize(objective, n_trials=1000)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
