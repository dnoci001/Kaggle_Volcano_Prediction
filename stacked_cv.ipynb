{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import sys\n",
    "import glob\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from time import ctime\n",
    "import matplotlib.pyplot as plt\n",
    "from pandas.plotting import register_matplotlib_converters\n",
    "register_matplotlib_converters()\n",
    "sns.set_style('darkgrid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_frags = glob.glob(\"./train_fft/*\")\n",
    "test_frags = glob.glob(\"./test_fft/*\")\n",
    "train = pd.read_csv(\"train.csv\")\n",
    "Y = pd.Series(0, index=np.arange(len(train_frags)))\n",
    "\n",
    "i = 0\n",
    "for file in train_frags:\n",
    "    start = './train_fft/'\n",
    "    end = '.csv'\n",
    "    seg_id = file[file.find(start)+len(start):file.rfind(end)]\n",
    "    t2e = int(train.loc[train['segment_id'] == int(seg_id)]['time_to_eruption'].values)\n",
    "    Y.iloc[i] = t2e\n",
    "    i = i + 1\n",
    "\n",
    "test_id = pd.Series(0, index=np.arange(len(test_frags)))    \n",
    "i = 0\n",
    "for file in test_frags:\n",
    "    start = './test_fft/'\n",
    "    end = '.csv'\n",
    "    seg_id = file[file.find(start)+len(start):file.rfind(end)]\n",
    "\n",
    "    test_id.iloc[i] = seg_id\n",
    "    i = i + 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "timescaler = preprocessing.StandardScaler().fit(Y.to_numpy().reshape(-1,1))\n",
    "Y = pd.Series(timescaler.transform(Y.to_numpy().reshape(-1,1)).reshape(-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_pca = pd.read_csv(\"pca_30.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = all_pca[:len(train_frags)]\n",
    "X_test = all_pca[-len(test_frags):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fold 0 started at Wed Dec  2 18:04:25 2020\n",
      "\n",
      "Fold 1 started at Wed Dec  2 18:04:57 2020\n",
      "\n",
      "Fold 2 started at Wed Dec  2 18:05:40 2020\n",
      "\n",
      "Fold 3 started at Wed Dec  2 18:06:23 2020\n",
      "\n",
      "Fold 4 started at Wed Dec  2 18:07:06 2020\n",
      "R2 0.936720 min -1.6513822439804584\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model._bayes import ARDRegression\n",
    "from sklearn.ensemble._weight_boosting import AdaBoostRegressor\n",
    "from sklearn.linear_model._bayes import BayesianRidge\n",
    "from sklearn.tree._classes import DecisionTreeRegressor \n",
    "from sklearn.linear_model._coordinate_descent import ElasticNetCV\n",
    "from sklearn.ensemble._forest import ExtraTreesRegressor\n",
    "from sklearn.gaussian_process._gpr import GaussianProcessRegressor\n",
    "from sklearn.linear_model._glm.glm import GeneralizedLinearRegressor\n",
    "from sklearn.ensemble._gb import GradientBoostingRegressor\n",
    "from sklearn.ensemble._hist_gradient_boosting.gradient_boosting import HistGradientBoostingRegressor\n",
    "from sklearn.linear_model._huber import HuberRegressor\n",
    "from sklearn.isotonic import IsotonicRegression \n",
    "from sklearn.neighbors._regression import KNeighborsRegressor\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from sklearn.linear_model._least_angle import LarsCV\n",
    "from sklearn.linear_model._coordinate_descent import LassoCV\n",
    "from sklearn.linear_model._least_angle import LassoLarsCV\n",
    "from sklearn.linear_model._least_angle import LassoLarsIC\n",
    "from sklearn.linear_model._base import LinearRegression\n",
    "from sklearn.svm._classes import LinearSVR\n",
    "from sklearn.neural_network._multilayer_perceptron import MLPRegressor\n",
    "from sklearn.svm._classes import NuSVR\n",
    "from sklearn.linear_model._omp import OrthogonalMatchingPursuitCV\n",
    "from sklearn.linear_model._passive_aggressive import PassiveAggressiveRegressor\n",
    "from sklearn.neighbors._regression import RadiusNeighborsRegressor\n",
    "from sklearn.ensemble._forest import RandomForestRegressor\n",
    "from sklearn.linear_model._ridge import RidgeCV\n",
    "from sklearn.linear_model._stochastic_gradient import SGDRegressor\n",
    "from sklearn.svm._classes import SVR\n",
    "from sklearn.linear_model._glm.glm import TweedieRegressor\n",
    "from sklearn.ensemble import StackingRegressor\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "n_fold = 5\n",
    "r2 = 0\n",
    "predicted_times = np.zeros(len(X_test))\n",
    "cv = KFold(n_splits=n_fold, shuffle=True, random_state=420)\n",
    "\n",
    "estimators = [('est0', MLPRegressor(max_iter=10000)),\n",
    " ('est1', BayesianRidge()),\n",
    " ('est2', RidgeCV()),\n",
    " ('est3', KNeighborsRegressor()),\n",
    " ('est4', ElasticNetCV()),\n",
    " ('est5', NuSVR(max_iter=100000))]\n",
    "\n",
    "festimator = GradientBoostingRegressor()\n",
    "\n",
    "model = StackingRegressor(estimators=estimators,final_estimator=festimator)\n",
    "\n",
    "# model.fit(train_pca, ertime)\n",
    "\n",
    "\n",
    "for fold_n, (train_index, valid_index) in enumerate(cv.split(X)):\n",
    "    print('\\nFold', fold_n, 'started at', ctime())\n",
    "\n",
    "    X_train = X.iloc[train_index,:]\n",
    "    X_valid = X.iloc[valid_index,:]\n",
    "    \n",
    "    Y_train = Y.iloc[train_index]\n",
    "    Y_valid = Y.iloc[valid_index]\n",
    "    \n",
    "    model.fit(X_train,Y_train)\n",
    "    r2 += model.score(X_valid,Y_valid)\n",
    "    predicted_times += model.predict(X_test)\n",
    "        \n",
    "r2 /= n_fold\n",
    "predicted_times /= n_fold\n",
    "\n",
    "print('R2 {:3f} min {:}'.format(r2,predicted_times.min()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_times = timescaler.inverse_transform(predicted_times)\n",
    "predicted_times2 = predicted_times\n",
    "#MLP R2 0.938642 min -1.7697310024988808"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame({\n",
    "        \"segment_id\": test_id,\n",
    "        \"time_to_eruption\": predicted_times2\n",
    "    })\n",
    "\n",
    "submission.to_csv('submission_4.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
