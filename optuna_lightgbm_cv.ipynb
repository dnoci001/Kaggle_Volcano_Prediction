{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import sys\n",
    "import glob\n",
    "import math\n",
    "import optuna\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from time import ctime\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import r2_score\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import KFold\n",
    "from pandas.plotting import register_matplotlib_converters\n",
    "register_matplotlib_converters()\n",
    "sns.set_style('darkgrid')\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_frags = glob.glob(\"./train_fft/*\")\n",
    "test_frags = glob.glob(\"./test_fft/*\")\n",
    "train = pd.read_csv(\"train.csv\")\n",
    "Y = pd.Series(0, index=np.arange(len(train_frags)))\n",
    "\n",
    "i = 0\n",
    "for file in train_frags:\n",
    "    start = './train_fft/'\n",
    "    end = '.csv'\n",
    "    seg_id = file[file.find(start)+len(start):file.rfind(end)]\n",
    "    t2e = int(train.loc[train['segment_id'] == int(seg_id)]['time_to_eruption'].values)\n",
    "    Y.iloc[i] = t2e\n",
    "    i = i + 1\n",
    "\n",
    "test_id = pd.Series(0, index=np.arange(len(test_frags)))    \n",
    "i = 0\n",
    "for file in test_frags:\n",
    "    start = './test_fft/'\n",
    "    end = '.csv'\n",
    "    seg_id = file[file.find(start)+len(start):file.rfind(end)]\n",
    "\n",
    "    test_id.iloc[i] = seg_id\n",
    "    i = i + 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    params = { \"objective\": \"regression\",\n",
    "              \"metric\": \"mae\",\n",
    "              \"verbosity\": -1,\n",
    "              \"boosting_type\": \"gbdt\",\n",
    "              \"num_iterations\": 1000,\n",
    "              \"early_stopping_round\": 5,\n",
    "              \"n_jobs\": -1,\n",
    "              'num_leaves': trial.suggest_int(\"nleaves\", 32, 256),\n",
    "              'bagging_fraction': trial.suggest_float('bagfrac',0.7,1.0),\n",
    "              'bagging_freq': trial.suggest_int(\"bagfreq\", 1, 10),\n",
    "              'feature_fraction': trial.suggest_float('featfrac',0.7,1.0),\n",
    "              'lambda_l1': trial.suggest_float(\"lambda_l1\", 1e-6, 10.0, log=True),\n",
    "              'lambda_l2': trial.suggest_float(\"lambda_l2\", 1e-6, 10.0, log=True),\n",
    "              'min_child_samples': trial.suggest_int(\"minchild\", 1, 100)}\n",
    "    \n",
    "    all_pca = pd.read_csv('pca_30.csv')\n",
    "\n",
    "    X = all_pca[:len(train_frags)]\n",
    "    X_test = all_pca[-len(test_frags):]\n",
    "\n",
    "    n_fold = 5\n",
    "    mae, r2 = [], []\n",
    "    predicted_times = np.zeros(len(X_test))\n",
    "    cv = KFold(n_splits=n_fold, shuffle=True, random_state=42)\n",
    "\n",
    "\n",
    "    for fold_n, (train_index, valid_index) in enumerate(cv.split(X)):\n",
    "\n",
    "        X_train = X.iloc[train_index,:]\n",
    "        X_valid = X.iloc[valid_index,:]\n",
    "\n",
    "        Y_train = Y.iloc[train_index]\n",
    "        Y_valid = Y.iloc[valid_index]\n",
    "\n",
    "        dtrain = lgb.Dataset(X_train, label=Y_train)\n",
    "        dval = lgb.Dataset(X_valid, label=Y_valid)\n",
    "\n",
    "        model = lgb.train( params, dtrain, valid_sets=[dtrain, dval], verbose_eval=-1 )\n",
    "\n",
    "        y_pred = model.predict(X_valid)\n",
    "        mae.append(mean_absolute_error(Y_valid, y_pred))\n",
    "        r2.append(r2_score(Y_valid, y_pred))\n",
    "\n",
    "        predicted_times += model.predict(X_test)\n",
    "\n",
    "    predicted_times /= n_fold\n",
    "\n",
    "    filename = 'fold_submission' + str(trial.number) + '.csv'\n",
    "    submission = pd.DataFrame({\n",
    "            \"segment_id\": test_id,\n",
    "            \"time_to_eruption\": predicted_times\n",
    "        })\n",
    "\n",
    "    submission.to_csv(filename, index=False)\n",
    "    \n",
    "    return np.mean(mae)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "study_name = 'lgbm_study' \n",
    "study = optuna.create_study(direction=\"minimize\",load_if_exists = True,study_name=study_name, storage='sqlite:///lgbm_study.db')\n",
    "study.optimize(objective, n_trials=1000)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
